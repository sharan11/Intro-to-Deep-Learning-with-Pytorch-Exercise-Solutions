{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training Neural Networks Solution.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sharan11/Intro-to-Deep-Learning-with-Pytorch-Exercise-Solutions/blob/master/Training_Neural_Networks_Solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGFWUM5BBs5M",
        "colab_type": "code",
        "outputId": "d20a54f4-70c9-47b8-8934-b8f09accad55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,), (0.5,)),\n",
        "                              ])\n",
        "# Download and load the training data\n",
        "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:01, 8505979.31it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/28881 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 130887.88it/s]           \n",
            "  0%|          | 0/1648877 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 2121133.55it/s]                            \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 49121.41it/s]            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8Di-ITTB2iO",
        "colab_type": "code",
        "outputId": "71b294ea-796a-4f60-f458-437a62cf8729",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10))\n",
        "\n",
        "# Define the loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Get our data\n",
        "images, labels = next(iter(trainloader))\n",
        "# Flatten images\n",
        "images = images.view(images.shape[0], -1)\n",
        "print(images.shape)\n",
        "\n",
        "# Forward pass, get our logits\n",
        "logits = model(images)\n",
        "# Calculate the loss with the logits and the labels\n",
        "loss = criterion(logits, labels)\n",
        "\n",
        "print(loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 784])\n",
            "tensor(2.3149, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBb4qMTdCiV3",
        "colab_type": "text"
      },
      "source": [
        "**Exercise:** Build a model that returns the log-softmax as the output and calculate the loss using the negative log likelihood loss. Note that for nn.LogSoftmax and F.log_softmax you'll need to set the dim keyword argument appropriately. dim=0 calculates softmax across the rows, so each column sums to 1, while dim=1 calculates across the columns so each row sums to 1. Think about what you want the output to be and choose dim appropriately."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zcxxrwCCDzg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dcdc312f-ae43-495c-eba8-9b1c2ef0fc97"
      },
      "source": [
        "## Solution\n",
        "# TODO: Build a feed-forward network\n",
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64,10),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "# TODO: Define the loss\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "### Run this to check your work\n",
        "# Get our data\n",
        "images, labels = next(iter(trainloader))\n",
        "# Flatten images\n",
        "images = images.view(images.shape[0], -1)\n",
        "\n",
        "# Forward pass, get our logits\n",
        "logits = model(images)\n",
        "# Calculate the loss with the logits and the labels\n",
        "loss = criterion(logits, labels)\n",
        "\n",
        "print(loss)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.2990, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaH8-G3JGY63",
        "colab_type": "text"
      },
      "source": [
        "## AutoGrad"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-W8kM-9Dib8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b4fb2eb6-ef06-4d15-d526-d81e4ada4d34"
      },
      "source": [
        "# Example\n",
        "\n",
        "x = torch.randn(2,2, requires_grad=True)\n",
        "print(x)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-1.6529,  0.4632],\n",
            "        [-1.3790,  0.8256]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paZosfObJLhg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1665c943-3880-4d82-a084-05a7c86566b2"
      },
      "source": [
        "y = x**2\n",
        "print(y)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2.7320, 0.2145],\n",
            "        [1.9017, 0.6816]], grad_fn=<PowBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afrcMFX3JOwQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e4bc92f9-fb44-4b58-fafd-1eede8a06c70"
      },
      "source": [
        "## grad_fn shows the function that generated this variable\n",
        "print(y.grad_fn)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<PowBackward0 object at 0x7f268e774898>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Dqtxn-JJTne",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b7e86f03-5b57-445d-8fcb-9d95bb05ee84"
      },
      "source": [
        "z = y.mean()\n",
        "print(z)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.3825, grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifMqjwboJb8d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "30cdc7c0-f8ef-4be6-93fb-e250400584b9"
      },
      "source": [
        "print(x.grad)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMAd7PW0J1_m",
        "colab_type": "text"
      },
      "source": [
        "To calculate the gradients, you need to run the .backward method on a Variable, z for example. This will calculate the gradient for z with respect to x"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ep3k_cANJhcK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "523ba0bf-06ec-4805-83fd-b72b757960f8"
      },
      "source": [
        "z.backward()\n",
        "print(x.grad)\n",
        "print(x/2)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.8264,  0.2316],\n",
            "        [-0.6895,  0.4128]])\n",
            "tensor([[-0.8264,  0.2316],\n",
            "        [-0.6895,  0.4128]], grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVdTYGR-L9LY",
        "colab_type": "text"
      },
      "source": [
        "### Loss and Autograd together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSnrQ96aJ78l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build a feed-forward network\n",
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "images, labels = next(iter(trainloader))\n",
        "images = images.view(images.shape[0], -1)\n",
        "\n",
        "logps = model(images)\n",
        "loss = criterion(logps, labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mN6lKuqO8Sz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "41c03357-01ff-4909-ea9c-aed117092451"
      },
      "source": [
        "print('Before backward pass: \\n', model[0].weight.grad)\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "print('After backward pass: \\n', model[0].weight.grad)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before backward pass: \n",
            " None\n",
            "After backward pass: \n",
            " tensor([[ 0.0022,  0.0022,  0.0022,  ...,  0.0022,  0.0022,  0.0022],\n",
            "        [-0.0017, -0.0017, -0.0017,  ..., -0.0017, -0.0017, -0.0017],\n",
            "        [-0.0011, -0.0011, -0.0011,  ..., -0.0011, -0.0011, -0.0011],\n",
            "        ...,\n",
            "        [ 0.0005,  0.0005,  0.0005,  ...,  0.0005,  0.0005,  0.0005],\n",
            "        [ 0.0011,  0.0011,  0.0011,  ...,  0.0011,  0.0011,  0.0011],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRE4hniNQoif",
        "colab_type": "text"
      },
      "source": [
        "### Training the network!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGr7akfcO_Pi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import optim\n",
        "\n",
        "# Optimizers require the parameters to optimize and a learning rate\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsULdfH1VWSJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "da8b7e8e-da13-4d32-f6fe-2a87c65a73e7"
      },
      "source": [
        "print('Initial weights - ', model[0].weight)\n",
        "\n",
        "images, labels = next(iter(trainloader))\n",
        "images.resize_(64, 784)\n",
        "\n",
        "# Clear the gradients, do this because gradients are accumulated\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# Forward pass, then backward pass, then update weights\n",
        "output = model(images)\n",
        "loss = criterion(output, labels)\n",
        "loss.backward()\n",
        "print('Gradient -', model[0].weight.grad)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial weights -  Parameter containing:\n",
            "tensor([[-0.0138, -0.0302, -0.0155,  ...,  0.0002,  0.0012, -0.0131],\n",
            "        [ 0.0250,  0.0184, -0.0347,  ...,  0.0013, -0.0111, -0.0197],\n",
            "        [-0.0323,  0.0087,  0.0035,  ..., -0.0176, -0.0188, -0.0291],\n",
            "        ...,\n",
            "        [ 0.0009,  0.0034, -0.0327,  ..., -0.0185,  0.0080,  0.0190],\n",
            "        [ 0.0350,  0.0220,  0.0028,  ...,  0.0156,  0.0060, -0.0048],\n",
            "        [-0.0147,  0.0243,  0.0066,  ...,  0.0034,  0.0051,  0.0125]],\n",
            "       requires_grad=True)\n",
            "Gradient - tensor([[ 0.0061,  0.0061,  0.0061,  ...,  0.0061,  0.0061,  0.0061],\n",
            "        [-0.0037, -0.0037, -0.0037,  ..., -0.0037, -0.0037, -0.0037],\n",
            "        [-0.0027, -0.0027, -0.0027,  ..., -0.0027, -0.0027, -0.0027],\n",
            "        ...,\n",
            "        [ 0.0005,  0.0005,  0.0005,  ...,  0.0005,  0.0005,  0.0005],\n",
            "        [ 0.0007,  0.0007,  0.0007,  ...,  0.0007,  0.0007,  0.0007],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3dyZOJUWKSR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "78316947-bfb4-406d-ad69-76dca0db2828"
      },
      "source": [
        "# Take an update step and few the new weights\n",
        "optimizer.step()\n",
        "print('Updated weights - ', model[0].weight)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated weights -  Parameter containing:\n",
            "tensor([[-0.0138, -0.0302, -0.0155,  ...,  0.0001,  0.0011, -0.0132],\n",
            "        [ 0.0250,  0.0185, -0.0347,  ...,  0.0014, -0.0111, -0.0197],\n",
            "        [-0.0323,  0.0087,  0.0036,  ..., -0.0176, -0.0188, -0.0290],\n",
            "        ...,\n",
            "        [ 0.0009,  0.0034, -0.0327,  ..., -0.0185,  0.0080,  0.0190],\n",
            "        [ 0.0350,  0.0220,  0.0028,  ...,  0.0156,  0.0060, -0.0048],\n",
            "        [-0.0147,  0.0243,  0.0066,  ...,  0.0034,  0.0051,  0.0125]],\n",
            "       requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gui_tDr2YSbE",
        "colab_type": "text"
      },
      "source": [
        "### Training for real"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDeTacLZYZpp",
        "colab_type": "text"
      },
      "source": [
        "**Exercise**: Implement the training pass for our network. If you implemented it correctly, you should see the training loss drop with each epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVVHLVefXIu_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "881785da-8657-4de7-d7ff-9ecb37adbadc"
      },
      "source": [
        "## Solution\n",
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
        "\n",
        "epochs = 5\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in trainloader:\n",
        "        # Flatten MNIST images into a 784 long vector\n",
        "        images = images.view(images.shape[0], -1)\n",
        "    \n",
        "        # TODO: Training pass\n",
        "        optimizer.zero_grad()\n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss: 1.9976958523172814\n",
            "Training loss: 0.9550237140930029\n",
            "Training loss: 0.5515303273063733\n",
            "Training loss: 0.44509589381373005\n",
            "Training loss: 0.3962491429023651\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJvbcFgubrPX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "b6139272-b578-4777-dd4f-a46cdc679702"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/3bd7dea850e936d8cb44adda8200e4e2b5d627e3/intro-to-pytorch/helper.py"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-08 14:36:17--  https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/3bd7dea850e936d8cb44adda8200e4e2b5d627e3/intro-to-pytorch/helper.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2813 (2.7K) [text/plain]\n",
            "Saving to: ‘helper.py’\n",
            "\n",
            "\rhelper.py             0%[                    ]       0  --.-KB/s               \rhelper.py           100%[===================>]   2.75K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-11-08 14:36:17 (67.2 MB/s) - ‘helper.py’ saved [2813/2813]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fOQx_zpclB9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "def view_classify(img, ps, version=\"MNIST\"):\n",
        "    ''' Function for viewing an image and it's predicted classes.\n",
        "    '''\n",
        "    ps = ps.data.numpy().squeeze()\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
        "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
        "    ax1.axis('off')\n",
        "    ax2.barh(np.arange(10), ps)\n",
        "    ax2.set_aspect(0.1)\n",
        "    ax2.set_yticks(np.arange(10))\n",
        "    if version == \"MNIST\":\n",
        "        ax2.set_yticklabels(np.arange(10))\n",
        "    elif version == \"Fashion\":\n",
        "        ax2.set_yticklabels(['T-shirt/top',\n",
        "                            'Trouser',\n",
        "                            'Pullover',\n",
        "                            'Dress',\n",
        "                            'Coat',\n",
        "                            'Sandal',\n",
        "                            'Shirt',\n",
        "                            'Sneaker',\n",
        "                            'Bag',\n",
        "                            'Ankle Boot'], size='small');\n",
        "    ax2.set_title('Class Probability')\n",
        "    ax2.set_xlim(0, 1.1)\n",
        "\n",
        "    plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nM74bTqRbYRF",
        "colab_type": "text"
      },
      "source": [
        "With the network trained, we can check out it's predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChWCONdFas_5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "8790c0aa-5250-46bf-8c6a-7e78522b2c4c"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "images, labels = next(iter(trainloader))\n",
        "\n",
        "img = images[0].view(1, 784)\n",
        "# Turn off gradients to speed up this part\n",
        "with torch.no_grad():\n",
        "    logps = model(img)\n",
        "\n",
        "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
        "ps = torch.exp(logps)\n",
        "view_classify(img.view(1, 28, 28), ps)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAADsCAYAAAAhDDIOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKElSL1lQkqRe+r+5zks95Cn2HgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHoobfA4bjAe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "722c6295-e474-4fc7-8523-4af0606cfe59"
      },
      "source": [
        "running_loss"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "371.6816960424185"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfrRh3OfdoPP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "47735430-9b85-4c88-c58a-496c006227ec"
      },
      "source": [
        "len(trainloader)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "938"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZ3IIxL9dsBn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}