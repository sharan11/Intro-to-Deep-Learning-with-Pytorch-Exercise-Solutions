{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Saving and Loading Models.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sharan11/Intro-to-Deep-Learning-with-Pytorch-Exercise-Solutions/blob/master/Saving_and_Loading_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqEbmISpxvxs",
        "colab_type": "text"
      },
      "source": [
        "### Saving and Loading Models\n",
        "In this notebook, I'll show you how to save and load models with PyTorch. This is important because you'll often want to load previously trained models to use in making predictions or to continue training on new data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjyNQ_kwxloA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import fc_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rfWyDlRx5oD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "ab5bf130-34d2-4594-86b0-95aac0725ee2"
      },
      "source": [
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,), (0.5,))])\n",
        "# Download and load the training data\n",
        "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Download and load the test data\n",
        "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 40960/26421880 [00:00<01:11, 368375.81it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "26427392it [00:00, 67727663.26it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-images-idx3-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 372458.24it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4423680it [00:00, 22593970.22it/s]                         \n",
            "8192it [00:00, 143486.03it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8xoeRpY2E6D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "c713b678-b42d-40ee-9317-83ecb3c78f6d"
      },
      "source": [
        "import helper_pt\n",
        "image, label = next(iter(trainloader))\n",
        "helper_pt.imshow(image[0,:]);"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAc8AAAHPCAYAAAA1eFErAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nngAQEk8ACP0XBKIJjrVbJKUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 231,
              "height": 231
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa9BMwn32gS5",
        "colab_type": "text"
      },
      "source": [
        "### Train a Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_6WTNd12ark",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the network, define the criterion and optimizer\n",
        "\n",
        "model = fc_model.Network(784, 10, [512, 256, 128])\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A72JOA4B2kaS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "outputId": "2acf6f6a-56fe-460e-f076-3db6c9839635"
      },
      "source": [
        "fc_model.train(model, trainloader, testloader, criterion, optimizer, epochs=2)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/2..  Training Loss: 1.721..  Test Loss: 1.036..  Test Accuracy: 0.667\n",
            "Epoch: 1/2..  Training Loss: 1.069..  Test Loss: 0.778..  Test Accuracy: 0.718\n",
            "Epoch: 1/2..  Training Loss: 0.902..  Test Loss: 0.661..  Test Accuracy: 0.750\n",
            "Epoch: 1/2..  Training Loss: 0.791..  Test Loss: 0.662..  Test Accuracy: 0.759\n",
            "Epoch: 1/2..  Training Loss: 0.761..  Test Loss: 0.629..  Test Accuracy: 0.759\n",
            "Epoch: 1/2..  Training Loss: 0.726..  Test Loss: 0.602..  Test Accuracy: 0.771\n",
            "Epoch: 1/2..  Training Loss: 0.704..  Test Loss: 0.583..  Test Accuracy: 0.790\n",
            "Epoch: 1/2..  Training Loss: 0.716..  Test Loss: 0.566..  Test Accuracy: 0.796\n",
            "Epoch: 1/2..  Training Loss: 0.661..  Test Loss: 0.560..  Test Accuracy: 0.792\n",
            "Epoch: 1/2..  Training Loss: 0.630..  Test Loss: 0.546..  Test Accuracy: 0.799\n",
            "Epoch: 1/2..  Training Loss: 0.656..  Test Loss: 0.531..  Test Accuracy: 0.808\n",
            "Epoch: 1/2..  Training Loss: 0.639..  Test Loss: 0.537..  Test Accuracy: 0.800\n",
            "Epoch: 1/2..  Training Loss: 0.609..  Test Loss: 0.550..  Test Accuracy: 0.798\n",
            "Epoch: 1/2..  Training Loss: 0.636..  Test Loss: 0.520..  Test Accuracy: 0.802\n",
            "Epoch: 1/2..  Training Loss: 0.588..  Test Loss: 0.502..  Test Accuracy: 0.811\n",
            "Epoch: 1/2..  Training Loss: 0.570..  Test Loss: 0.511..  Test Accuracy: 0.815\n",
            "Epoch: 1/2..  Training Loss: 0.560..  Test Loss: 0.498..  Test Accuracy: 0.813\n",
            "Epoch: 1/2..  Training Loss: 0.578..  Test Loss: 0.497..  Test Accuracy: 0.815\n",
            "Epoch: 1/2..  Training Loss: 0.559..  Test Loss: 0.485..  Test Accuracy: 0.821\n",
            "Epoch: 1/2..  Training Loss: 0.602..  Test Loss: 0.489..  Test Accuracy: 0.818\n",
            "Epoch: 1/2..  Training Loss: 0.580..  Test Loss: 0.508..  Test Accuracy: 0.819\n",
            "Epoch: 1/2..  Training Loss: 0.571..  Test Loss: 0.506..  Test Accuracy: 0.812\n",
            "Epoch: 1/2..  Training Loss: 0.591..  Test Loss: 0.472..  Test Accuracy: 0.827\n",
            "Epoch: 2/2..  Training Loss: 0.539..  Test Loss: 0.493..  Test Accuracy: 0.820\n",
            "Epoch: 2/2..  Training Loss: 0.561..  Test Loss: 0.517..  Test Accuracy: 0.807\n",
            "Epoch: 2/2..  Training Loss: 0.576..  Test Loss: 0.486..  Test Accuracy: 0.823\n",
            "Epoch: 2/2..  Training Loss: 0.541..  Test Loss: 0.472..  Test Accuracy: 0.825\n",
            "Epoch: 2/2..  Training Loss: 0.551..  Test Loss: 0.465..  Test Accuracy: 0.827\n",
            "Epoch: 2/2..  Training Loss: 0.535..  Test Loss: 0.459..  Test Accuracy: 0.832\n",
            "Epoch: 2/2..  Training Loss: 0.551..  Test Loss: 0.467..  Test Accuracy: 0.825\n",
            "Epoch: 2/2..  Training Loss: 0.515..  Test Loss: 0.470..  Test Accuracy: 0.827\n",
            "Epoch: 2/2..  Training Loss: 0.520..  Test Loss: 0.475..  Test Accuracy: 0.826\n",
            "Epoch: 2/2..  Training Loss: 0.534..  Test Loss: 0.457..  Test Accuracy: 0.835\n",
            "Epoch: 2/2..  Training Loss: 0.506..  Test Loss: 0.463..  Test Accuracy: 0.831\n",
            "Epoch: 2/2..  Training Loss: 0.529..  Test Loss: 0.464..  Test Accuracy: 0.828\n",
            "Epoch: 2/2..  Training Loss: 0.537..  Test Loss: 0.471..  Test Accuracy: 0.830\n",
            "Epoch: 2/2..  Training Loss: 0.581..  Test Loss: 0.445..  Test Accuracy: 0.835\n",
            "Epoch: 2/2..  Training Loss: 0.542..  Test Loss: 0.449..  Test Accuracy: 0.838\n",
            "Epoch: 2/2..  Training Loss: 0.532..  Test Loss: 0.444..  Test Accuracy: 0.843\n",
            "Epoch: 2/2..  Training Loss: 0.544..  Test Loss: 0.449..  Test Accuracy: 0.835\n",
            "Epoch: 2/2..  Training Loss: 0.507..  Test Loss: 0.437..  Test Accuracy: 0.843\n",
            "Epoch: 2/2..  Training Loss: 0.517..  Test Loss: 0.447..  Test Accuracy: 0.839\n",
            "Epoch: 2/2..  Training Loss: 0.489..  Test Loss: 0.444..  Test Accuracy: 0.834\n",
            "Epoch: 2/2..  Training Loss: 0.531..  Test Loss: 0.439..  Test Accuracy: 0.839\n",
            "Epoch: 2/2..  Training Loss: 0.525..  Test Loss: 0.438..  Test Accuracy: 0.841\n",
            "Epoch: 2/2..  Training Loss: 0.473..  Test Loss: 0.447..  Test Accuracy: 0.838\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIDCRc_U2rZj",
        "colab_type": "text"
      },
      "source": [
        "### Saving and loading networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUHSpWto2oSd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "79b79c0f-4b66-49ae-cf45-d1bb1625230e"
      },
      "source": [
        "print(\"Our model: \\n\\n\", model, '\\n')\n",
        "print(\"The state dict keys: \\n\\n\", model.state_dict().keys())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our model: \n",
            "\n",
            " Network(\n",
            "  (hidden_layers): ModuleList(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
            "  )\n",
            "  (output): Linear(in_features=128, out_features=10, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ") \n",
            "\n",
            "The state dict keys: \n",
            "\n",
            " odict_keys(['hidden_layers.0.weight', 'hidden_layers.0.bias', 'hidden_layers.1.weight', 'hidden_layers.1.bias', 'hidden_layers.2.weight', 'hidden_layers.2.bias', 'output.weight', 'output.bias'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQCrO7qQ3F3w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), 'checkpoint.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrV_aFqA3O04",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "bd23b734-1121-4303-8be3-60223a8eaf42"
      },
      "source": [
        "state_dict = torch.load('checkpoint.pth')\n",
        "print(state_dict.keys())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "odict_keys(['hidden_layers.0.weight', 'hidden_layers.0.bias', 'hidden_layers.1.weight', 'hidden_layers.1.bias', 'hidden_layers.2.weight', 'hidden_layers.2.bias', 'output.weight', 'output.bias'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XKGw7FR3Svu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "outputId": "c2923db1-aeca-4e4e-a57c-f3c5ca751434"
      },
      "source": [
        "# Try this\n",
        "model = fc_model.Network(784, 10, [400, 200, 100])\n",
        "# This will throw an error because the tensor sizes are wrong!\n",
        "model.load_state_dict(state_dict)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-cc11e1013989>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfc_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# This will throw an error because the tensor sizes are wrong!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    837\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 839\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    840\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Network:\n\tsize mismatch for hidden_layers.0.weight: copying a param with shape torch.Size([512, 784]) from checkpoint, the shape in current model is torch.Size([400, 784]).\n\tsize mismatch for hidden_layers.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([400]).\n\tsize mismatch for hidden_layers.1.weight: copying a param with shape torch.Size([256, 512]) from checkpoint, the shape in current model is torch.Size([200, 400]).\n\tsize mismatch for hidden_layers.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([200]).\n\tsize mismatch for hidden_layers.2.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([100, 200]).\n\tsize mismatch for hidden_layers.2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([100]).\n\tsize mismatch for output.weight: copying a param with shape torch.Size([10, 128]) from checkpoint, the shape in current model is torch.Size([10, 100])."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7XabHPw3ZWW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This is how to save the model\n",
        "checkpoint = {'input_size': 784,\n",
        "              'output_size': 10,\n",
        "              'hidden_layers': [each.out_features for each in model.hidden_layers],\n",
        "              'state_dict': model.state_dict()}\n",
        "\n",
        "torch.save(checkpoint, 'checkpoint.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9EMuHHx3x3t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_checkpoint(filepath):\n",
        "    checkpoint = torch.load(filepath)\n",
        "    model = fc_model.Network(checkpoint['input_size'],\n",
        "                             checkpoint['output_size'],\n",
        "                             checkpoint['hidden_layers'])\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KF_hJTyy35Nr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "7ffa341d-8403-4691-b553-12e3475bd73a"
      },
      "source": [
        "model = load_checkpoint('checkpoint.pth')\n",
        "print(model)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Network(\n",
            "  (hidden_layers): ModuleList(\n",
            "    (0): Linear(in_features=784, out_features=400, bias=True)\n",
            "    (1): Linear(in_features=400, out_features=200, bias=True)\n",
            "    (2): Linear(in_features=200, out_features=100, bias=True)\n",
            "  )\n",
            "  (output): Linear(in_features=100, out_features=10, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LWyh9Iw37xw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}